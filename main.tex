\documentclass[11pt]{article}

% Language setting
\usepackage[turkish]{babel}
\usepackage{pythonhighlight}

\usepackage[a4paper,top=2cm,bottom=2cm,left=2cm,right=2cm,marginparwidth=2cm]{geometry}

% Useful packages
\usepackage{amsmath}
\usepackage{graphicx}
\usepackage[colorlinks=true, allcolors=blue]{hyperref}
\usepackage{verbatim}
\usepackage{fancyhdr} % for header and footer
\usepackage{titlesec}
\usepackage{parskip}

\setlength{\parindent}{0pt}

\titleformat{\subsection}[runin]{\bfseries}{\thesubsection}{1em}{}

\pagestyle{fancy} % activate the custom header/footer

% define the header/footer contents
\lhead{\small{23BLM-4014 Yapay Sinir Ağları Ara Sınav Soru ve Cevap Kağıdı}}
\rhead{\small{Dr. Ulya Bayram}}
\lfoot{}
\rfoot{}

% remove header/footer on first page
\fancypagestyle{firstpage}{
  \lhead{}
  \rhead{}
  \lfoot{}
  \rfoot{\thepage}
}
 

\title{Çanakkale Onsekiz Mart Üniversitesi, Mühendislik Fakültesi, Bilgisayar Mühendisliği Akademik Dönem 2022-2023\\
Ders: BLM-4014 Yapay Sinir Ağları/Bahar Dönemi\\ 
ARA SINAV SORU VE CEVAP KAĞIDI\\
Dersi Veren Öğretim Elemanı: Dr. Öğretim Üyesi Ulya Bayram}
\author{%
\begin{minipage}{\textwidth}
\raggedright
Öğrenci Adı Soyadı: Ahmet Arda Giritli\\ % Adınızı soyadınızı ve öğrenci numaranızı noktaların yerine yazın
Öğrenci No: 180401014
\end{minipage}%
}

\date{14 Nisan 2023}

\begin{document}
\maketitle

\vspace{-.5in}
\section*{Açıklamalar:}
\begin{itemize}
    \item Vizeyi çözüp, üzerinde aynı sorular, sizin cevaplar ve sonuçlar olan versiyonunu bu formatta PDF olarak, Teams üzerinden açtığım assignment kısmına yüklemeniz gerekiyor. Bu bahsi geçen PDF'i oluşturmak için LaTeX kullandıysanız, tex dosyasının da yer aldığı Github linkini de ödevin en başına (aşağı url olarak) eklerseniz bonus 5 Puan! (Tavsiye: Overleaf)
    \item Çözümlerde ya da çözümlerin kontrolünü yapmada internetten faydalanmak, ChatGPT gibi servisleri kullanmak serbest. Fakat, herkesin çözümü kendi emeğinden oluşmak zorunda. Çözümlerinizi, cevaplarınızı aşağıda belirttiğim tarih ve saate kadar kimseyle paylaşmayınız. 
    \item Kopyayı önlemek için Github repository'lerinizin hiçbirini \textbf{14 Nisan 2023, saat 15:00'a kadar halka açık (public) yapmayınız!} (Assignment son yükleme saati 13:00 ama internet bağlantısı sorunları olabilir diye en fazla ekstra 2 saat daha vaktiniz var. \textbf{Fakat 13:00 - 15:00 arası yüklemelerden -5 puan!}
    \item Ek puan almak için sağlayacağınız tüm Github repository'lerini \textbf{en geç 15 Nisan 2023 15:00'da halka açık (public) yapmış olun linklerden puan alabilmek için!}
    \item \textbf{14 Nisan 2023, saat 15:00'dan sonra gönderilen vizeler değerlendirilmeye alınmayacak, vize notu olarak 0 (sıfır) verilecektir!} Son anda internet bağlantısı gibi sebeplerden sıfır almayı önlemek için assignment kısmından ara ara çözümlerinizi yükleyebilirsiniz yedekleme için. Verilen son tarih/saatte (14 Nisan 2023, saat 15:00) sistemdeki en son yüklü PDF geçerli olacak.
    \item Çözümlerin ve kodların size ait ve özgün olup olmadığını kontrol eden bir algoritma kullanılacaktır. Kopya çektiği belirlenen vizeler otomatikman 0 (sıfır) alacaktır. Bu nedenle çözümlerinizi ve kodlarınızı yukarıda sağladığım gün ve saatlere kadar kimseyle paylaşmayınız.
    \item Bu vizeden alınabilecek en yüksek not 100'dür. Toplam aldığınız puan 100'ü geçerse, aldığınız not 100'e sabitlenecektir.
    \item LaTeX kullanarak PDF oluşturanlar öz geçmişlerine LaTeX bildiklerini de eklemeyi unutmasınlar :)
    \item Bu vizedeki soruların çözümleri ve tex dosyası için istediğiniz kadar sayıda Github repository'si oluşturabilirsiniz. Sadece yukarıda belirttiğim tarihlerde (14 Nisan 2023 saat 15:00 ile 15 Nisan 2023 saat 15:00 arasında) public yapmayı/halka açmayı ve Github profilinizi de öz geçmişinize eklemeyi unutmayın :)
    \item Bilgisayarınıza hiçbir program kurmadan, Overleaf, Google Colab, Kaggle gibi ortamlar üzerinden bu vizeyi tamamlamanız mümkün. İyi çalışmalar!!
\end{itemize}

\url{https://github.com/ardagiritli/YapaySinirTex}

\newpage
\section{(Toplam 10 Puan) Hopfield Networks:}

\subsection{(2 Puan)} \textbf{ChatGPT’ye size Hopfield Network’ler ile ilgili detaylı bilgi vermesini isteyin. Sorduğunuz soruyu, ChatGPT'nin çıkartığı cevabı aşağı koyun. Bu cevapta anlamadığınız terimleri de ChatGPT’ye sorup, sorduğunuz soruları ve ChatGPT’nin verdiği cevapları da sırayla aşağı koyun.}

Hopfield Network’ler ile ilgili detaylı bilgi ver.
Hopfield ağları, sinir ağları alanında kullanılan bir tür geri beslemeli yapay sinir ağıdır. Bu ağlar, özellikle bellek ve tanıma sorunlarında kullanılan çözümleme araçlarıdır.
Hopfield ağları, birbirine bağlı bir dizi nöron (veya hücre) kümesidir. Bu nöronlar, birbirleriyle bağlantılıdır ve birbirleri arasında sinyal iletişimi sağlarlar. Her bir nöron, iki durum arasında geçiş yapabilen birçok bağlantıya sahiptir: pozitif veya negatif.
Hopfield ağları, asıl olarak asenkron dinamiklere dayanır. Bu, ağdaki nöronların birbiriyle iletişim kurması ve belirli bir deseni tanımlamak için bir araya gelmesiyle gerçekleşir. Desen, bir dizi nöron durumunun belirli bir kombinasyonunu ifade eder.
Hopfield ağları, enerji fonksiyonu kullanarak bir deseni tanımlarlar. Bu enerji fonksiyonu, ağdaki her nöronun durumu için bir enerji değeri hesaplar. Desenin doğru bir şekilde tanınması, ağın enerji fonksiyonunun minimuma indirilmesiyle elde edilir.
Hopfield ağları, çok sayıda uygulamada kullanılmaktadır. Özellikle, çeşitli desen tanıma, veri sıkıştırma, optimize etme ve otomatik öğrenme görevlerinde kullanılır. Bunlar arasında örneğin resim tanıma, dil modelleme, örüntü tanıma, seçim ve tahmin gibi görevler yer alır.
Hopfield ağları, sinir ağları alanındaki en popüler yapay sinir ağı modellerinden biridir. Bunlar, basit bir yapısı olan ve birçok farklı uygulamada kullanılabilen çok yönlü ağlar olarak kabul edilir.

Geri beslemeli yapay sinir ağı nedir?
Geri beslemeli yapay sinir ağı, çıktıların ardışık bir dizi işleme tabi tutulduğu ve çıktıların bir önceki adımda aldığı değerlerin sonraki adımlara geri beslendiği bir yapay sinir ağı türüdür. Bu geri besleme, ağın bir tür hafıza oluşturmasına ve önceki adımlardaki çıktıları gelecekteki adımların işleme sürecinde kullanmasına olanak tanır.
Geri beslemeli yapay sinir ağları, özellikle zaman serisi verilerinin analizi, kontrol sistemleri, doğal dil işleme, sinyal işleme, robotik ve tahmin modelleri gibi alanlarda kullanılır. Bu ağların tipik bir örneği, gizli katmanlarda geri besleme bağlantıları içeren bir yapay sinir ağı olan rekürsif sinir ağıdır (RNN). RNN'ler, girdilerin ve çıktıların sıralı olduğu problemlerde oldukça etkilidir ve özellikle doğal dil işleme alanında sıklıkla kullanılır.
Geri beslemeli yapay sinir ağları, yapay sinir ağları alanında önemli bir rol oynamaktadır ve birçok farklı uygulamada kullanılmaktadır. Bu ağlar, özellikle zaman serilerinin analizi, tahmini ve kontrolü, dil modelleme, sınıflandırma, regresyon ve desen tanıma gibi görevlerde başarılı sonuçlar verirler.


\subsection{(8 Puan)} \textbf{ChatGPT’nin açıklamalarından ne anladığınızı buraya kendi kelimelerinizle özetleyin. Örneğin ``Hopfield Network nedir? Ne işe yarar? Neden bilmemiz gerekir bunu? Gerçek hayatta kullanılıyor mu?'' gibi. Anlamadığınız kısımlar varsa ve ChatGPT’nin açıklamaları yeterli gelmezse internet dahil farklı kaynaklardan araştırıp, bilgilerin doğruluğunu sorgulamakta serbestsiniz. Konuyu doğru anlayıp anlamamanız puana etki edecektir. Kullandığınız kaynakları da belirtin!}

Hopfield Network geri beslemeli bir yapay sinir ağıdır. İki aşamadan oluşur. Depolama ve işleme aşamalarıdır. Depoladığımız veriler bellekten çekilerek işlenir ve önümüzdeki veri ile işlenir. Hopfield Networkü eşleme, tanıma işlemlerinde sıkça kullanırız. Örnek verirsek; örüntü tanıma, resim tanıma, şifreleme işlemlerinde sıkça kullanılır. Bu nedenle yapay sinir ağları kullanılan yerlerde sıkça karşımıza çıkan bir yapay sinir ağıdır. Günlük hayatımızda ise Hopfield ağlarını temel alan bir sürü yapı bulunmaktadır. Yüz tanıma, araç plaka tanıma ve ses tanıma gibi örnekler verebiliriz.

\section{(Toplam 10 Puan) Boltzman Machine:}

\subsection{(2 Puan)} \textbf{ChatGPT’ye size Boltzman Machine ilgili detaylı bilgi vermesini isteyin. Sorduğunuz soruyu, ChatGPT'nin çıkartığı cevabı aşağı koyun. Bu cevapta anlamadığınız terimleri de ChatGPT’ye sorup, sorduğunuz soruları ve ChatGPT’nin verdiği cevapları da sırayla aşağı koyun.}

Boltzman Machine ilgili detaylı bilgi ver.
Boltzmann makinesi, yapay sinir ağları alanında bir tür olasılıksal yapay sinir ağıdır. Boltzmann makinesi, enerji işlevleri ve olasılık dağılımları arasındaki bağlantıları kullanarak belirli bir girdiye uygun bir çıktı üretir. Bu makine, düşük seviyeli özellikleri, örüntü tanıma, doğal dil işleme ve olasılıksal çıkarım gibi uygulamalarda kullanılır.
Bir Boltzmann makinesi, bir nöron tabanlı bir modeldir ve nöronlar, sinapslar ve enerji fonksiyonlarından oluşur. Makinenin çalışma prensibi, bir enerji fonksiyonunun minimizasyonu ve olasılık dağılımlarının öğrenilmesine dayanır.
Bir Boltzmann makinesi, iki tür nöronu içerir: gizli nöronlar ve görülebilen nöronlar. Gizli nöronlar, ağın içindeki gizli bir katmanı temsil ederken, görülebilen nöronlar ise ağın girdi ve çıktılarını temsil eder.
Bir Boltzmann makinesi, bir enerji fonksiyonu ile tanımlanır. Bu enerji fonksiyonu, ağın tüm nöronlarındaki duruma göre hesaplanır. Bu fonksiyonun en küçük değerine ulaşmak, makinenin çıktısının doğru olmasını sağlar.
Boltzmann makinesi, öğrenme sırasında öğrenim verilerine göre ağırlıkları ayarlar ve ağın belirli bir girdiye karşılık olarak çıktı üretmesini sağlar. Öğrenme sırasında, ağa verilen öğrenim verileri, ağın görülebilen nöronlarının dağılımını etkiler. Bu dağılım, ağın gizli nöronlarına geri beslenir ve ağın öğrenme kapasitesini arttırır.
Bir Boltzmann makinesi, düşük seviyeli özellikleri çıkarmak, örüntü tanıma, doğal dil işleme, olasılıksal çıkarım, veri boyut azaltma ve yeniden örnekleme gibi birçok farklı uygulamada kullanılır.


\subsection{(8 Puan)} \textbf{ChatGPT’nin açıklamalarından ne anladığınızı buraya kendi kelimelerinizle özetleyin. Örneğin ``Boltzman Machine nedir? Ne işe yarar? Neden bilmemiz gerekir bunu? Gerçek hayatta kullanılıyor mu?'' gibi. Anlamadığınız kısımlar varsa ve ChatGPT’nin açıklamaları yeterli gelmezse internet dahil farklı kaynaklardan araştırıp, bilgilerin doğruluğunu sorgulamakta serbestsiniz. Konuyu doğru anlayıp anlamamanız puana etki edecektir. Kullandığınız kaynakları da belirtin!}

Bozalt makinesi olasılık tabanlı bir yapay sinir ağıdır. Enerji işlevleri ve olasılık dağılımları kullanarak en düşük enerjiye ulaşmaya çalışır. Bozalt makine ayrıca iki tür nöron içerir bunlar görünür ve gizli nöronlar. Gizli nöronlar gizli bir katmanı temsil eder ve gizli nöronlar ise ağın öğrenmesi için kullanılarak verimliliği arıttırır. Görünür nöronlarda ise girdi çıktı işlemleri gerçekleşir. Olasılıksal çıkarım, doğal dil işleme ve veri boyutu azalmayı örnek olarak verebiliriz.

\section{(Toplam 10 Puan) Markov Assumption ve Markov Chain:}

\subsection{(2 Puan)} \textbf{ChatGPT’ye size Markov assumption ve Markov Chain ilgili detaylı bilgi vermesini isteyin. Sorduğunuz soruyu, ChatGPT'nin çıkartığı cevabı aşağı koyun. Bu cevapta anlamadığınız terimleri de ChatGPT’ye sorup, sorduğunuz soruları ve ChatGPT’nin verdiği cevapları da sırayla aşağı koyun.}

Markov assumption ve Markov Chain ilgili detaylı bilgi ver.
Markov varsayımı veya Markov özellikleri, bir sürecin gelecekteki durumlarının yalnızca mevcut durumuna bağlı olduğu bir olasılık teorisi kavramıdır. Bu varsayıma göre, geçmiş durumlar gelecekteki durumları etkilemez ve sadece mevcut durum gelecekteki durumu belirler. Bu nedenle, Markov süreci, önceki durumların belleklerinde tutulmadığı bir süreçtir.
Markov süreci, genellikle Markov zinciri olarak da adlandırılır. Markov zinciri, belirli bir sürecin birbirini izleyen adımlarında durumların belirli bir dizi olduğu bir matematiksel modeldir. Bu zincir, bir dizi olasılık dağılımı ile tanımlanır ve geçmiş durumlardan bağımsız olarak sadece mevcut durum ve sonraki durumlar arasındaki geçişlerin olasılıklarını belirler.
Markov zincirleri, çeşitli uygulama alanlarında kullanılır, örneğin finansal piyasalarda fiyat hareketlerinin modellemesi, doğal dil işlemede dil modellemesi ve arama motoru sıralama algoritmalarında kullanılan PageRank algoritması gibi alanlarda kullanılır.
Markov zinciri, birbirini izleyen adımlarda durumlar arasındaki geçişlerin olasılıklarını belirleyen bir geçiş matrisi kullanılarak tanımlanır. Geçiş matrisi, her bir durumun sonraki durumlarla ilişkisini gösteren bir matristir ve tüm satırlarının toplamı 1'dir.
Markov zincirleri, mevcut durumdan sonraki duruma geçiş olasılıklarını hesaplayan birçok farklı yöntem kullanılarak analiz edilir. Bu yöntemler arasında Monte Carlo yöntemleri, Gibbs örnekleme, ölçeklendirme algoritmaları ve diğerleri bulunur.
Markov zincirleri, yalnızca geçmiş durumların bellekte tutulmadığı bir süreç olduğu için bellek sınırlaması ile ilişkilendirilir. Bu nedenle, Markov zincirleri, belirli bir bellek sınırlaması içinde belirli bir zaman aralığında geçmiş durumları hesaba katarak gelecekteki durumları tahmin etmek için kullanılabilir.
Monte Carlo yöntemleri nedir?
Monte Carlo yöntemleri, rastgele sayılar kullanarak matematiksel problemlerin çözümünü bulma yöntemleridir. Bu yöntemler, analitik veya hesaplamalı çözümlerin bulunmasının zor olduğu, yüksek boyutlu problemlerde kullanılır.
Monte Carlo yöntemleri, birçok farklı uygulama alanında kullanılır, örneğin fizik, mühendislik, finans ve istatistik gibi alanlarda kullanılır. Bu yöntemler, genellikle bir problemi, rastgele sayılar üreterek simüle ederler ve bu simülasyon sonuçlarını kullanarak orijinal problemin çözümünü bulmaya çalışırlar.
Monte Carlo yöntemleri, doğrudan rastgele sayı üretme, örnek alma ve istatistiksel analiz gibi temel adımlardan oluşur. Bu yöntemler, bir problemdeki belirli bir kısıtlama veya özellikle ilgilenilen özelliklerin istatistiksel dağılımını hesaplamak için kullanılabilir.
Monte Carlo yöntemlerinin bir örneği, rastgele yürüyüş yöntemidir. Bu yöntem, belirli bir alan içinde rastgele bir konumda başlar ve ardışık adımlarla ilerleyerek nihai hedefe doğru yaklaşmaya çalışır. Bu yöntem, optimize edilmesi zor olan çok değişkenli fonksiyonların minimum veya maksimum noktalarını bulmak için kullanılabilir.
Monte Carlo yöntemleri, çok sayıda rastgele sayı ürettiği için bilgisayar tabanlı simülasyonlarla uygulanır. Bu nedenle, modern bilgisayarlarla Monte Carlo yöntemleri büyük ölçekte kullanılabilir hale gelmiştir.
Gibbs örnekleme, ölçeklendirme algoritmaları nedir?
Gibbs örnekleme, Monte Carlo yöntemlerinin bir türüdür ve özellikle Markov Zincir Monte Carlo (MCMC) yöntemleri için kullanılır. Bu yöntem, bir olasılık dağılımının örneklerini elde etmek için kullanılır.
Gibbs örnekleme, birçok boyutlu olasılık dağılımları ile çalışmak için tasarlanmıştır. Bu yöntem, bir olasılık dağılımının her bir boyutundan ayrı ayrı örneklemler elde eder ve her boyuttaki örneklemler diğer boyutları kullanarak hesaplanır.
Gibbs örnekleme algoritması, aşağıdaki adımları içerir:
Başlangıçta, örneklemek istediğimiz olasılık dağılımının boyutlarında rastgele bir nokta seçilir.
Seçilen noktadaki her boyutun örneklemesi için, diğer boyutların sabit olduğu varsayılır. Bu, her bir boyut için koşullu olasılık dağılımının hesaplanmasına izin verir.
Her bir boyutta koşullu olasılık dağılımına göre bir örnek seçilir ve yeni bir nokta elde edilir.
Yeni noktanın seçilme olasılığı, önceki noktanın seçilme olasılığına göre hesaplanır ve örnekleme işlemi tekrarlanır.
Ölçeklendirme algoritmaları, büyük veri kümelerinde veya yüksek boyutlu veri setlerinde kullanılan bir veri işleme yöntemidir. Bu algoritmalar, verileri daha küçük parçalara bölmek ve her parçayı ayrı ayrı işlemek suretiyle hesaplama süresini azaltır.
Ölçeklendirme algoritmaları, veri madenciliği ve yapay zeka gibi birçok farklı alanda kullanılır. Bu algoritmalar arasında, paralel hesaplama, böl ve fethet, ağaç yapılandırması ve kümeleme gibi farklı yaklaşımlar bulunur. Bu algoritmalar, büyük veri kümelerinde verimli işlem yapmak için gereklidir.


\subsection{(8 Puan)} \textbf{ChatGPT’nin açıklamalarından ne anladığınızı buraya kendi kelimelerinizle özetleyin. Örneğin ``Markov assumption ve Markov Chain nedir? Ne işe yarar? Neden bilmemiz gerekir bunu? Gerçek hayatta kullanılıyor mu?'' gibi. Anlamadığınız kısımlar varsa ve ChatGPT’nin açıklamaları yeterli gelmezse internet dahil farklı kaynaklardan araştırıp, bilgilerin doğruluğunu sorgulamakta serbestsiniz. Konuyu doğru anlayıp anlamamanız puana etki edecektir. Kullandığınız kaynakları da belirtin!}

Markov varsayımı Hopfield ağlarının aksine bellekte veri barındırmaz. Aksine anlık işlem yaparak sadece bulunduğu durumun analizini yapar. Geçmiş o anki duruma etki etmez. Kullanım alanı göz önüne alındığında finansal hareketlerin analizi örnek verilebilir. Özellikle mühendislik alanında çokça kullanılmaktadır. Matematiksel verilerin modellenmesinde etkili bir kavramdır.

\section{(Toplam 20 Puan) Feed Forward:}
 
\begin{itemize}
    \item Forward propagation için, input olarak şu X matrisini verin (tensöre çevirmeyi unutmayın):\\
    $X = \begin{bmatrix}
        1 & 2 & 3\\
        4 & 5 & 6
        \end{bmatrix}$
    Satırlar veriler (sample'lar), kolonlar öznitelikler (feature'lar).
    \item Bir adet hidden layer olsun ve içinde tanh aktivasyon fonksiyonu olsun
    \item Hidden layer'da 50 nöron olsun
    \item Bir adet output layer olsun, tek nöronu olsun ve içinde sigmoid aktivasyon fonksiyonu olsun
\end{itemize}

Tanh fonksiyonu:\\
$f(x) = \frac{exp(x) - exp(-x)}{exp(x) + exp(-x)}$
\vspace{.2in}

Sigmoid fonksiyonu:\\
$f(x) = \frac{1}{1 + exp(-x)}$

\vspace{.2in}
 \textbf{Pytorch kütüphanesi ile, ama kütüphanenin hazır aktivasyon fonksiyonlarını kullanmadan, formülünü verdiğim iki aktivasyon fonksiyonunun kodunu ikinci haftada yaptığımız gibi kendiniz yazarak bu yapay sinir ağını oluşturun ve aşağıdaki üç soruya cevap verin.}
 
\subsection{(10 Puan)} \textbf{Yukarıdaki yapay sinir ağını çalıştırmadan önce pytorch için Seed değerini 1 olarak set edin, kodu aşağıdaki kod bloğuna ve altına da sonucu yapıştırın:}

% Latex'de kod koyabilirsiniz python formatında. Aşağıdaki örnekleri silip içine kendi kodunuzu koyun
\begin{python}
import torch
import torch.nn as nn
torch.manual_seed(1)

x = ([[1, 2, 3], [4, 5, 6]])

tensorx = torch.tensor(x,dtype=torch.float32)
a = tensorx.view(1,6)

def fsigmoid(x):

  return 1 / (1 + torch.exp(-x))

def ftanh(x):
  return (torch.exp(x) - torch.exp(-x)) / (torch.exp(x) + torch.exp(-x))

class MyModel(nn.Module):  

    def __init__(self):
        super(MyModel, self).__init__()
        self.hidden = nn.Linear(2*3, 50)
        self.output = nn.Linear(50, 1)

    def forward(self, x):
        x = ftanh(self.hidden(x))
        x = fsigmoid(self.output(x))
        return x

b = MyModel()
output = b(a)
output

\end{python}

tensor([[0.5932]]

\subsection{(5 Puan)} \textbf{Yukarıdaki yapay sinir ağını çalıştırmadan önce Seed değerini öğrenci numaranız olarak değiştirip, kodu aşağıdaki kod bloğuna ve altına da sonucu yapıştırın:}

\begin{python}
import torch
import torch.nn as nn
torch.manual_seed(180401014)

x = ([[1, 2, 3], [4, 5, 6]])

tensorx = torch.tensor(x,dtype=torch.float32)
a = tensorx.view(1,6)

def fsigmoid(x):

  return 1 / (1 + torch.exp(-x))

def ftanh(x):
  return (torch.exp(x) - torch.exp(-x)) / (torch.exp(x) + torch.exp(-x))

class MyModel(nn.Module):  

    def __init__(self):
        super(MyModel, self).__init__()
        self.hidden = nn.Linear(2*3, 50)
        self.output = nn.Linear(50, 1)

    def forward(self, x):
        x = ftanh(self.hidden(x))
        x = fsigmoid(self.output(x))
        return x

b = MyModel()
output = b(a)
output
\end{python}

tensor([[0.4704]]

\subsection{(5 Puan)} \textbf{Kodlarınızın ve sonuçlarınızın olduğu jupyter notebook'un Github repository'sindeki linkini aşağıdaki url kısmının içine yapıştırın. İlk sayfada belirttiğim gün ve saate kadar halka açık (public) olmasın:}
% size ait Github olmak zorunda, bu vize için ayrı bir github repository'si açıp notebook'u onun içine koyun. Kendine ait olmayıp da arkadaşının notebook'unun linkini paylaşanlar 0 alacak.

\url{https://github.com/ardagiritli/YapaySinirAglar-}

\section{(Toplam 40 Puan) Multilayer Perceptron (MLP):} 
\textbf{Bu bölümdeki sorularda benim vize ile beraber paylaştığım Prensesi İyileştir (Cure The Princess) Veri Seti parçaları kullanılacak. Hikaye şöyle (soruyu çözmek için hikaye kısmını okumak zorunda değilsiniz):} 

``Bir zamanlar, çok uzaklarda bir ülkede, ağır bir hastalığa yakalanmış bir prenses yaşarmış. Ülkenin kralı ve kraliçesi onu iyileştirmek için ellerinden gelen her şeyi yapmışlar, ancak denedikleri hiçbir çare işe yaramamış.

Yerel bir grup köylü, herhangi bir hastalığı iyileştirmek için gücü olduğu söylenen bir dizi sihirli malzemeden bahsederek kral ve kraliçeye yaklaşmış. Ancak, köylüler kral ile kraliçeyi, bu malzemelerin etkilerinin patlayıcı olabileceği ve son zamanlarda yaşanan kuraklıklar nedeniyle bu malzemelerden sadece birkaçının herhangi bir zamanda bulunabileceği konusunda uyarmışlar. Ayrıca, sadece deneyimli bir simyacı bu özelliklere sahip patlayıcı ve az bulunan malzemelerin belirli bir kombinasyonunun prensesi iyileştireceğini belirleyebilecekmiş.

Kral ve kraliçe kızlarını kurtarmak için umutsuzlar, bu yüzden ülkedeki en iyi simyacıyı bulmak için yola çıkmışlar. Dağları tepeleri aşmışlar ve nihayet "Yapay Sinir Ağları Uzmanı" olarak bilinen yeni bir sihirli sanatın ustası olarak ün yapmış bir simyacı bulmuşlar.

Simyacı önce köylülerin iddialarını ve her bir malzemenin alınan miktarlarını, ayrıca iyileşmeye yol açıp açmadığını incelemiş. Simyacı biliyormuş ki bu prensesi iyileştirmek için tek bir şansı varmış ve bunu doğru yapmak zorundaymış. (Original source: \url{https://www.kaggle.com/datasets/unmoved/cure-the-princess})

(Buradan itibaren ChatGPT ve Dr. Ulya Bayram'a ait hikayenin devamı)

Simyacı, büyülü bileşenlerin farklı kombinasyonlarını analiz etmek ve denemek için günler harcamış. Sonunda birkaç denemenin ardından prensesi iyileştirecek çeşitli karışım kombinasyonları bulmuş ve bunları bir veri setinde toplamış. Daha sonra bu veri setini eğitim, validasyon ve test setleri olarak üç parçaya ayırmış ve bunun üzerinde bir yapay sinir ağı eğiterek kendi yöntemi ile prensesi iyileştirme ihtimalini hesaplamış ve ikna olunca kral ve kraliçeye haber vermiş. Heyecanlı ve umutlu olan kral ve kraliçe, simyacının prensese hazırladığı ilacı vermesine izin vermiş ve ilaç işe yaramış ve prenses hastalığından kurtulmuş.

Kral ve kraliçe, kızlarının hayatını kurtardığı için simyacıya krallıkta kalması ve çalışmalarına devam etmesi için büyük bir araştırma bütçesi ve çok sayıda GPU'su olan bir server vermiş. İyileşen prenses de kendisini iyileştiren yöntemleri öğrenmeye merak salıp, krallıktaki üniversitenin bilgisayar mühendisliği bölümüne girmiş ve mezun olur olmaz da simyacının yanında, onun araştırma grubunda çalışmaya başlamış. Uzun yıllar birlikte krallıktaki insanlara, hayvanlara ve doğaya faydalı olacak yazılımlar geliştirmişler, ve simyacı emekli olduğunda prenses hem araştırma grubunun hem de krallığın lideri olarak hayatına devam etmiş.

Prenses, kendisini iyileştiren veri setini de, gelecekte onların izinden gidecek bilgisayar mühendisi prensler ve prensesler başkalarına faydalı olabilecek yapay sinir ağları oluşturmayı öğrensinler diye halka açmış ve sınavlarda kullanılmasını salık vermiş.''

\textbf{İki hidden layer'lı bir Multilayer Perceptron (MLP) oluşturun beşinci ve altıncı haftalarda yaptığımız gibi. Hazır aktivasyon fonksiyonlarını kullanmak serbest. İlk hidden layer'da 100, ikinci hidden layer'da 50 nöron olsun. Hidden layer'larda ReLU, output layer'da sigmoid aktivasyonu olsun.}

\textbf{Output layer'da kaç nöron olacağını veri setinden bakıp bulacaksınız. Elbette bu veriye uygun Cross Entropy loss yöntemini uygulayacaksınız. Optimizasyon için Stochastic Gradient Descent yeterli. Epoch sayınızı ve learning rate'i validasyon seti üzerinde denemeler yaparak (loss'lara overfit var mı diye bakarak) kendiniz belirleyeceksiniz. Batch size'ı 16 seçebilirsiniz.}

\subsection{(10 Puan)} \textbf{Bu MLP'nin pytorch ile yazılmış class'ının kodunu aşağı kod bloğuna yapıştırın:}

\begin{python}
import torch
import torch.nn as nn
import torch.optim as optim
from torch.utils.data import DataLoader, Dataset
from sklearn.model_selection import train_test_split
import numpy as np
import pandas as pd
import torchvision
import random


     

uploaded = files.upload()
     
Upload widget is only available when the cell has been executed in the current browser session. Please rerun this cell to enable.
Saving cure_the_princess_test.csv to cure_the_princess_test (5).csv
Saving cure_the_princess_train.csv to cure_the_princess_train (5).csv
Saving cure_the_princess_validation.csv to cure_the_princess_validation (5).csv

batch_size = 16
test_data = pd.read_csv("cure_the_princess_test.csv")
train_data = pd.read_csv("cure_the_princess_train.csv")
val_data = pd.read_csv("cure_the_princess_validation.csv")


test_X = test_data.iloc[:, :-1]
test_y = test_data.iloc[:, -1]

train_X = train_data.iloc[:, :-1]
train_y = train_data.iloc[:, -1]

val_X = val_data.iloc[:, :-1]
val_y = val_data.iloc[:, -1]


     

trainloader = torch.utils.data.DataLoader(train_data, batch_size=16,shuffle=True, num_workers=2)
valloader = torch.utils.data.DataLoader (val_data, batch_size=16,shuffle=False, num_workers=2)
testloader = torch.utils.data.DataLoader (test_data, batch_size=16, shuffle=False, num_workers=2)
     

class MLP(nn.Module):
    def __init__(self):
        super().__init__()
        self.fc1 = nn.Linear(train_X.shape[1], 100)
        self.fc2 = nn.Linear(100, 50)
        self.fc3 = nn.Linear100, len(np.unique(train_y))
        self.relu = nn.ReLU()
        self.sigmoid = nn.Sigmoid()

    def forward(self, x):
        x = self.relu(self.fc1(x))
        x = self.relu(self.fc2(x))
        x = self.sigmoid(self.fc3(x))
        return x

\end{python}

\subsection{(10 Puan)} \textbf{SEED=öğrenci numaranız set ettikten sonra altıncı haftada yazdığımız gibi training batch'lerinden eğitim loss'ları, validation batch'lerinden validasyon loss değerlerini hesaplayan kodu aşağıdaki kod bloğuna yapıştırın ve çıkan figürü de alta ekleyin.}

\begin{python}

 num_epochs = 10
train_losses = []
val_losses = []
model = MLP()
for epoch in range(num_epochs):
    train_loss = 0.0
    val_loss = 0.0
    
    
    model.train()
    for i, (inputs, labels) in enumerate(train_dataloader):
        optimizer.zero_grad()
        outputs = model(inputs)
        loss = criterion(outputs, labels)
        loss.backward()
        optimizer.step()
        train_loss += loss.item()
    train_loss /= len(train_dataloader)
    train_losses.append(train_loss)

    
    model.eval()
    with torch.no_grad():
        for i, (inputs, labels) in enumerate(val_dataloader):
            outputs = model(inputs)
            loss = criterion(outputs, labels)
            val_loss += loss.item()
        val_loss /= len(val_dataloader)
        val_losses.append(val_loss)

   
    print(f"Epoch {epoch+1}/{num_epochs}, Train Loss: {train_loss:.4f}, Validation Loss: {val_loss:.4f}")



\end{python}

% Figure aşağıda comment içindeki kısımdaki gibi eklenir.
\begin{comment}

\begin{figure}[ht!]
 
\end{figure}
\end{comment}

\subsection{(10 Puan)} \textbf{SEED=öğrenci numaranız set ettikten sonra altıncı haftada ödev olarak verdiğim gibi earlystopping'deki en iyi modeli kullanarak, Prensesi İyileştir test setinden accuracy, F1, precision ve recall değerlerini hesaplayan kodu yazın ve sonucu da aşağı yapıştırın. \%80'den fazla başarı bekliyorum test setinden. Daha düşükse başarı oranınız, nerede hata yaptığınızı bulmaya çalışın. \%90'dan fazla başarı almak mümkün (ben denedim).}

\begin{python}

\end{python}



\subsection{(5 Puan)} \textbf{Tüm kodların CPU'da çalışması ne kadar sürüyor hesaplayın. Sonra to device yöntemini kullanarak modeli ve verileri GPU'ya atıp kodu bir de böyle çalıştırın ve ne kadar sürdüğünü hesaplayın. Süreleri aşağıdaki tabloya koyun. GPU için Google Colab ya da Kaggle'ı kullanabilirsiniz, iki ortam da her hafta saatlerce GPU hakkı veriyor.}

\begin{table}[ht!]
 
    \begin{tabular}{c|c}
     
    \end{tabular}
   
\end{table}

\subsection{(3 Puan)} \textbf{Modelin eğitim setine overfit etmesi için elinizden geldiği kadar kodu gereken şekilde değiştirin, validasyon loss'unun açıkça yükselmeye başladığı, training ve validation loss'ları içeren figürü aşağı koyun ve overfit için yaptığınız değişiklikleri aşağı yazın. Overfit, tam bir çanak gibi olmalı ve yükselmeli. Ona göre parametrelerle oynayın.}



% Figür aşağı
\begin{comment}
\begin{figure}[ht!]
   
\end{figure}
\end{comment}

\subsection{(2 Puan)} \textbf{Beşinci soruya ait tüm kodların ve cevapların olduğu jupyter notebook'un Github linkini aşağıdaki url'e koyun.}

\url{}

\section{(Toplam 10 Puan)} \textbf{Bir önceki sorudaki Prensesi İyileştir problemindeki yapay sinir ağınıza seçtiğiniz herhangi iki farklı regülarizasyon yöntemi ekleyin ve aşağıdaki soruları cevaplayın.} 

\subsection{(2 puan)} \textbf{Kodlarda regülarizasyon eklediğiniz kısımları aşağı koyun:} 

\begin{python}

\end{python}

\subsection{(2 puan)} \textbf{Test setinden yeni accuracy, F1, precision ve recall değerlerini hesaplayıp aşağı koyun:}



\subsection{(5 puan)} \textbf{Regülarizasyon yöntemi seçimlerinizin sebeplerini ve sonuçlara etkisini yorumlayın:}



\subsection{(1 puan)} \textbf{Sonucun github linkini  aşağıya koyun:}

\url{}

\end{document}